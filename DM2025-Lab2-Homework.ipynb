{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Student Information**\n",
    "Name: Victor Lim Kai Xuan\n",
    "\n",
    "Student ID:613530019\n",
    "\n",
    "GitHub ID:victorlim98\n",
    "\n",
    "Kaggle name:victorlim98\n",
    "\n",
    "Kaggle private scoreboard snapshot: \n",
    "\n",
    "![pic_ranking.png](./pics/Kaggle.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Instructions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab we have divided the assignments into **three phases/parts**. The `first two phases` refer to the `exercises inside the Master notebooks` of the [DM2025-Lab2-Exercise Repo](https://github.com/difersalest/DM2025-Lab2-Exercise.git). The `third phase` refers to an `internal Kaggle competition` that we are gonna run among all the Data Mining students. Together they add up to `100 points` of your grade. There are also some `bonus points` to be gained if you complete `extra exercises` in the lab **(bonus 15 pts)** and in the `Kaggle Competition report` **(bonus 5 pts)**.\n",
    "\n",
    "**Environment recommendations to solve lab 2:**\n",
    "- **Phase 1 exercises:** Need GPU for training the models explained in that part, if you don't have a GPU in your laptop it is recommended to run in Colab or Kaggle for a faster experience, although with CPU they can still be solved but with a slower execution.\n",
    "- **Phase 2 exercises:** We use Gemini's API so everything can be run with only CPU without a problem.\n",
    "- **Phase 3 exercises:** For the competition you will probably need GPU to train your models, so it is recommended to use Colab or Kaggle if you don't have a laptop with a dedicated GPU.\n",
    "- **Optional Ollama Notebook (not graded):** You need GPU, at least 4GB of VRAM with 16 GB of RAM to run the local open-source LLM models. \n",
    "\n",
    "## **Phase 1 (30 pts):**\n",
    "\n",
    "1. __Main Exercises (25 pts):__ Do the **take home exercises** from Sections: `1. Data Preparation` to `9. High-dimension Visualization: t-SNE and UMAP`, in the [DM2025-Lab2-Master-Phase_1 Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_1.ipynb). Total: `8 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 3th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "## **Phase 2 (30 pts):**\n",
    "\n",
    "1. **Main Exercises (25 pts):** Do the remaining **take home exercises** from Section: `2. Large Language Models (LLMs)` in the [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb). Total: `5 exercises required from sections 2.1, 2.2, 2.4 and 2.6`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "3. **`Bonus (15 pts):`** Complete the bonus exercises in the [DM2025-Lab2-Master-Phase_2_Bonus Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Bonus.ipynb) and [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb) `where 2 exercises are counted as bonus from sections 2.3 and 2.5 in the main notebook`. Total: `7 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "## **Phase 3 (40 pts):**\n",
    "\n",
    "1. **Kaggle Competition Participation (30 pts):** Participate in the in-class **Kaggle Competition** regarding Emotion Recognition on Twitter by clicking in this link: **[Data Mining Class Kaggle Competition](https://www.kaggle.com/t/3a2df4c6d6b4417e8bf718ed648d7554)**. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20 pts of the 30 pts in this competition participation part.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**. Make sure to take a screenshot of your position at the end of the competition and store it as `pic_ranking.png` under the `pics` folder of this repository and rerun the cell **Student Information**.\n",
    "\n",
    "2. **Competition Report (10 pts)** A report section to be filled in inside this notebook in Markdown Format, we already provided you with the template below. You need to describe your work developing the model for the competition. The report should include a section describing briefly the following elements: \n",
    "* Your preprocessing steps.\n",
    "* The feature engineering steps.\n",
    "* Explanation of your model.\n",
    "\n",
    "* **`Bonus (5 pts):`**\n",
    "    * You will have to describe more detail in the previous steps.\n",
    "    * Mention different things you tried.\n",
    "    * Mention insights you gained. \n",
    "\n",
    "[Markdown Guide - Basic Syntax](https://www.markdownguide.org/basic-syntax/)\n",
    "\n",
    "**`Things to note for Phase 3:`**\n",
    "\n",
    "* **The code used for the competition should be in this Jupyter Notebook File** `DM2025-Lab2-Homework.ipynb`.\n",
    "\n",
    "* **Push the code used for the competition to your repository**.\n",
    "\n",
    "* **The code should have a clear separation for the same sections of the report, preprocessing, feature engineering and model explanation. Briefly comment your code for easier understanding, we provide a template at the end of this notebook.**\n",
    "\n",
    "* Showing the kaggle screenshot of the ranking plus the code in this notebook will ensure the validity of your participation and the report to obtain the corresponding points.\n",
    "\n",
    "After the competition ends you will have two days more to submit the `DM2025-Lab2-Homework.ipynb` with your report in markdown format and your code. Do everything **`BEFORE the deadline (Nov. 26th, 11:59 pm, Wednesday) to obtain 100% of the available points.`**\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding NTU Cool assignment.\n",
    "\n",
    "## **Deadlines:**\n",
    "\n",
    "![lab2_deadlines](./pics/lab2_deadlines.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Next you will find the template report with some simple markdown syntax explanations, use it to structure your content.\n",
    "\n",
    "You can delete the syntax suggestions after you use them.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# **Project Report**\n",
    "\n",
    "### 1.1 Preprocessing Steps\n",
    "To prepare the raw data for analysis, I performed several stages of data cleaning and formatting. Since the data was distributed across multiple files (`json` for text, `csv` for labels), the first step was data integration.\n",
    "\n",
    "* **Data Parsing & Merging:** I parsed the nested JSON structure of `final_posts.json` to extract the raw text and `post_id`. This was merged with `data_identification.csv` to separate Train/Test splits and `emotion.csv` to align labels with the training text.\n",
    "* **Label Mapping:** The string labels ('joy', 'anger', etc.) were mapped to integers (0-5) for model compatibility.\n",
    "* **Text Cleaning (Evolution):**\n",
    "    * *Initial Approach:* For the baseline models (TF-IDF), I rigorously cleaned the text by removing special characters, URLs, and converting to lowercase.\n",
    "    * *Final Approach (Deep Learning):* For the RoBERTa model, I adopted a \"minimal cleaning\" strategy. I retained punctuation (like `!`, `?`) and capitalization because modern Transformer models utilize these cues to detect intensity and emotion (e.g., \"WHAT?!\" implies surprise/anger vs \"what?\" which implies confusion).\n",
    "\n",
    "\n",
    "### 1.2 Feature Engineering Steps\n",
    "\n",
    "My feature engineering strategy evolved significantly as I moved from statistical models to Deep Learning.\n",
    "\n",
    "* **Baseline (TF-IDF):**\n",
    "    * I used **TF-IDF (Term Frequency-Inverse Document Frequency)** to convert text into numerical vectors.\n",
    "    * To capture context, I enabled **N-grams (1, 3)**, allowing the model to see sequences of up to 3 words (e.g., \"not very happy\").\n",
    "    * I capped features at 15,000 to prevent the \"curse of dimensionality.\"\n",
    "\n",
    "* **Final Approach (Tokenization & Embeddings):**\n",
    "    * Instead of manual feature extraction, I used **Subword Tokenization** via the `roberta-base` tokenizer. This breaks words into meaningful chunks (e.g., \"playing\" -> \"play\" + \"ing\"), allowing the model to handle unknown words and morphology.\n",
    "    * The model learns **Contextual Embeddings**, where the vector representation of a word changes based on its neighbors (e.g., the word \"bank\" has a different vector in \"river bank\" vs. \"bank account\").\n",
    "\n",
    "### 1.3 Explanation of Your Model\n",
    "\n",
    "My final submission utilized a **Fine-Tuned RoBERTa (Robustly Optimized BERT Pretraining Approach)** model with a custom Weighted Loss function.\n",
    "\n",
    "* **Architecture:** RoBERTa is a Transformer-based architecture that uses Self-Attention mechanisms to process input text bidirectionally. Unlike standard BERT, RoBERTa is trained on more data and for longer, making it superior for subtle sentiment analysis tasks.\n",
    "* **Handling Class Imbalance (The Key Differentiator):**\n",
    "    * The dataset was highly imbalanced, with 'joy' being overrepresented and 'disgust/fear' being rare. Standard models biased heavily toward 'joy'.\n",
    "    * To fix this, I implemented a **Weighted Cross-Entropy Loss**. I calculated class weights based on the inverse frequency of each label in the training set.\n",
    "    * *Effect:* The model was penalized significantly more (approx. 5x-10x) for misclassifying rare classes like 'disgust' than for misclassifying 'joy'. This forced the model to learn the minority classes to minimize the global loss.\n",
    "* **Training Strategy:**\n",
    "    * **Optimizer:** AdamW with a very low learning rate (`2e-5`) to preserve pre-trained knowledge.\n",
    "    * **Regularization:** Used `EarlyStopping` with a patience of 2 epochs to prevent overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Bonus Section (5 pts Optional)\n",
    "\n",
    "**Add more detail in previous sections**\n",
    "\n",
    "### 2.1 Mention Different Things You Tried\n",
    "\n",
    "1.  **Baseline (Logistic Regression & LinearSVC):**\n",
    "    * *Method:* TF-IDF + Linear Support Vector Classifier.\n",
    "    * *Result:* Score ~0.45 (Macro F1).\n",
    "    * *Failure Analysis:* The model struggled with sarcasm and negation (e.g., \"I'm not exactly thrilled\"). It treated words as independent bags, losing semantic meaning.\n",
    "\n",
    "2.  **Ensemble Methods:**\n",
    "    * *Method:* A Voting Classifier combining LinearSVC, Logistic Regression, and Multinomial Naive Bayes.\n",
    "    * *Result:* Score ~0.55.\n",
    "    * *Observation:* While this smoothed out some variance, it still hit a ceiling because the underlying features (TF-IDF) were too simple.\n",
    "\n",
    "3.  **DistilBERT (First Deep Learning Attempt):**\n",
    "    * *Method:* Fine-tuning `distilbert-base-uncased`.\n",
    "    * *Result:* Score ~0.60.\n",
    "    * *Observation:* Deep learning understood context better, but the model still ignored the minority classes (Disgust/Fear), resulting in a high Accuracy but a mediocre F1 score.\n",
    "\n",
    "4.  **RoBERTa + Weighted Loss (Final):**\n",
    "    * *Method:* Switched to the heavier `roberta-base` and injected Class Weights into the Trainer's loss function.\n",
    "    * *Result:* Score > 0.67.\n",
    "    * *Success Factor:* The combination of a smarter model (RoBERTa) and the mathematical enforcement of minority class importance (Weighted Loss) provided the breakthrough.\n",
    "\n",
    "### 2.2 Mention Insights You Gained\n",
    "\n",
    "**The \"Accuracy Trap\":** In imbalanced datasets, a model can achieve 80% accuracy by predicting the majority class ('joy') for everything, but the F1 score will be terrible. Optimizing for **Macro F1** requires sacrificing some total accuracy to ensure rare classes are detected.\n",
    "* **Context is King:** Statistical methods (TF-IDF) fail on phrases like \"I am dying\" (which can be 'sadness' or 'joy' depending on context like \"...of laughter\"). Transformer models capture this nuance effectively.\n",
    "* **Data Cleaning for BERT:** Unlike traditional ML, \"cleaning\" text too much (removing punctuation/stops) actually *hurt* the Deep Learning model performance, as it removed valuable contextual cues.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`From here on starts the code section for the competition.`**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Competition Code**\n",
    "\n",
    "## 1. Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add the code related to the preprocessing steps in cells inside this section# Install necessary libraries\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# I am using Google Colab to run this competition, So the original cell output was at the google colab environment.\n",
    "drive.mount('/content/drive')\n",
    "DATA_PATH = '/content/drive/MyDrive/DM Kaggle/' \n",
    "\n",
    "\n",
    "# 1. Load Raw Data\n",
    "print(\"Loading data...\")\n",
    "with open(os.path.join(DATA_PATH, 'final_posts.json'), 'r') as f:\n",
    "    posts_data = json.load(f)\n",
    "\n",
    "df_ident = pd.read_csv(os.path.join(DATA_PATH, 'data_identification.csv'))\n",
    "df_emotion = pd.read_csv(os.path.join(DATA_PATH, 'emotion.csv'))\n",
    "\n",
    "# 2. Parse & Merge Data\n",
    "# Parse nested JSON\n",
    "posts_list = [entry['root']['_source']['post'] for entry in posts_data]\n",
    "df_posts = pd.DataFrame(posts_list).rename(columns={'post_id': 'id'})\n",
    "\n",
    "# Merge everything into one DataFrame\n",
    "df = df_posts.merge(df_ident, on='id').merge(df_emotion, on='id', how='left')\n",
    "\n",
    "# 3. Label Mapping\n",
    "label_map = {'anger': 0, 'disgust': 1, 'fear': 2, 'joy': 3, 'sadness': 4, 'surprise': 5}\n",
    "inverse_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "# 4. Minimal Text Cleaning\n",
    "df['text'] = df['text'].astype(str)\n",
    "\n",
    "print(f\"Data Loaded. Total rows: {len(df)}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add the code related to the feature engineering steps in cells inside this section\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# 1. Prepare Train/Test Splits\n",
    "train_df = df[df['split'] == 'train'].copy()\n",
    "train_df['label'] = train_df['emotion'].map(label_map).astype(int)\n",
    "\n",
    "# Stratified Split to ensure validation set has same distribution as training\n",
    "train_split, val_split = train_test_split(\n",
    "    train_df, \n",
    "    test_size=0.15, \n",
    "    random_state=42, \n",
    "    stratify=train_df['label']\n",
    ")\n",
    "\n",
    "# Convert to Hugging Face Dataset objects\n",
    "ds_train = Dataset.from_pandas(train_split[['text', 'label']])\n",
    "ds_val = Dataset.from_pandas(val_split[['text', 'label']])\n",
    "\n",
    "test_df = df[df['split'] == 'test'].copy()\n",
    "ds_test = Dataset.from_pandas(test_df[['text']])\n",
    "\n",
    "# 2. Tokenization (The \"Feature Engineering\" of NLP)\n",
    "model_name = \"roberta-base\"\n",
    "print(f\"Loading Tokenizer for {model_name}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # Padding='max_length' ensures all vectors are same size (128)\n",
    "    # Truncation=True cuts off extra long texts\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "print(\"Tokenizing datasets...\")\n",
    "tokenized_train = ds_train.map(tokenize_function, batched=True)\n",
    "tokenized_val = ds_val.map(tokenize_function, batched=True)\n",
    "tokenized_test = ds_test.map(tokenize_function, batched=True)\n",
    "\n",
    "# 3. Calculate Class Weights (Handling Imbalance)\n",
    "# This calculates how much attention the model should pay to each class.\n",
    "# Rare classes (Disgust, Fear) get higher weights.\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(train_df['label']),\n",
    "    y=train_df['label']\n",
    ")\n",
    "weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    weights_tensor = weights_tensor.to(\"cuda\")\n",
    "\n",
    "print(\"Class Weights Calculated:\", class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Implementation Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add the code related to the model implementation steps in cells inside this section\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "from torch import nn\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# 1. Define Custom Trainer with Weighted Loss\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        # Use CrossEntropyLoss with our calculated class weights\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# 2. Define Evaluation Metric\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    # Macro F1 is the competition metric\n",
    "    return {\"f1\": f1_score(labels, predictions, average='macro')}\n",
    "\n",
    "# 3. Initialize Model\n",
    "print(\"Initializing Model...\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=6)\n",
    "\n",
    "# 4. Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_roberta\",\n",
    "    learning_rate=2e-5,              # Low learning rate for fine-tuning\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,              # Max epochs\n",
    "    weight_decay=0.01,               # Regularization\n",
    "    eval_strategy=\"epoch\",           # Evaluate every epoch\n",
    "    save_strategy=\"epoch\",           # Save checkpoint every epoch\n",
    "    load_best_model_at_end=True,     # Load best model when finished\n",
    "    metric_for_best_model=\"f1\",      # Optimize for F1 score\n",
    "    save_total_limit=2,              # Save space\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# 5. Train\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)] # Stop if no improvement\n",
    ")\n",
    "\n",
    "print(\"Starting Training...\")\n",
    "trainer.train()\n",
    "\n",
    "# 6. Predict & Save\n",
    "print(\"Generating Predictions...\")\n",
    "predictions = trainer.predict(tokenized_test)\n",
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "\n",
    "# Convert IDs back to Labels\n",
    "test_df['emotion'] = [inverse_label_map[p] for p in preds]\n",
    "\n",
    "# Save to CSV\n",
    "submission_filename = 'submission.csv'\n",
    "test_df[['id', 'emotion']].to_csv(submission_filename, index=False)\n",
    "\n",
    "print(f\"SUCCESS: {submission_filename} created.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
